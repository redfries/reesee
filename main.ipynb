{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560f86cf",
   "metadata": {},
   "source": [
    "# Fundus Transfer‑Learning Pipeline\n",
    "\n",
    "This notebook‑style script:\n",
    "1. Installs & imports dependencies  \n",
    "2. Sets a global random seed  \n",
    "3. Clones RETFound_MAE & sets PYTHONPATH  \n",
    "4. Downloads pretrained weights  \n",
    "5. Detects your fundus dataset structure  \n",
    "6. Instantiates & loads the pretrained ViT  \n",
    "7. Inserts adapters for method=`'adapters'`  \n",
    "8. Defines four transfer‑learning modes  \n",
    "9. Runs a single experiment (`run_single`) and logs to CSV  \n",
    "10. Visualizes learning curves & confusion matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05426f3e",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# 1) Install & import dependencies\n",
    "import os, sys, random\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "try:\n",
    "    import timm, gdown, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "    from torchvision import transforms\n",
    "    from torchvision.datasets import ImageFolder\n",
    "    from torch.utils.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "except ImportError:\n",
    "    os.system(f\"{sys.executable} -m pip install --quiet torch torchvision timm gdown pandas numpy matplotlib seaborn scikit-learn tqdm\")\n",
    "    import timm, gdown, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "    from torchvision import transforms\n",
    "    from torchvision.datasets import ImageFolder\n",
    "    from torch.utils.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9035fb37",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Added RETFound_MAE to PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "# 2) Clone RETFound_MAE & fix PYTHONPATH\n",
    "def ensure_repo(name, url):\n",
    "    if not os.path.isdir(name):\n",
    "        print(f\"Cloning {name} from {url}…\")\n",
    "        os.system(f\"git clone {url} {name}\")\n",
    "\n",
    "ensure_repo(\"RETFound_MAE\", \"https://huggingface.co/open-eye/RETFound_MAE\")\n",
    "repo_path = os.path.join(os.getcwd(), \"RETFound_MAE\")\n",
    "if not os.path.isdir(repo_path):\n",
    "    raise FileNotFoundError(f\"RETFound_MAE not found at {repo_path}\")\n",
    "sys.path.insert(0, repo_path)\n",
    "print(\"✔ Added RETFound_MAE to PYTHONPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d45f73d4",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Model weights ready: RETFound_cfp_weights.pth\n"
     ]
    }
   ],
   "source": [
    "# 3) Download pretrained fundus weights\n",
    "WEIGHTS = \"RETFound_cfp_weights.pth\"\n",
    "if not os.path.isfile(WEIGHTS):\n",
    "    print(\"Downloading pretrained fundus weights…\")\n",
    "    os.system(f\"gdown --quiet --id 1l62zbWUFTlp214SvK6eMwPQZAzcwoeBE -O {WEIGHTS}\")\n",
    "print(\"✔ Model weights ready:\", WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1510f174",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR    = color_fundus_eye/color_fundus_eye\n",
      "Detected 10 classes: ['Central Serous Chorioretinopathy [Color Fundus]', 'Diabetic Retinopathy', 'Disc Edema', 'Glaucoma', 'Healthy', 'Macular Scar', 'Myopia', 'Pterygium', 'Retinal Detachment', 'Retinitis Pigmentosa']\n",
      "Train dir   = color_fundus_eye/color_fundus_eye/train (12989 images)\n",
      "Test dir    = color_fundus_eye/color_fundus_eye/test (3253 images)\n"
     ]
    }
   ],
   "source": [
    "# 4) Detect dataset folder (handles nested color_fundus_eye/color_fundus_eye)\n",
    "import os\n",
    "\n",
    "# top‐level folder name (change if yours differs)\n",
    "base = \"color_fundus_eye\"\n",
    "\n",
    "# Look for either color_fundus_eye/train or color_fundus_eye/color_fundus_eye/train\n",
    "if os.path.isdir(os.path.join(base, \"train\")):\n",
    "    DATA_DIR = base\n",
    "elif os.path.isdir(os.path.join(base, base, \"train\")):\n",
    "    DATA_DIR = os.path.join(base, base)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Cannot find 'train' under {base} or {base}/{base}\")\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "test_dir  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Auto‐discover your classes from the folders\n",
    "classes     = sorted(os.listdir(train_dir))\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Quick sanity‐print\n",
    "n_train = sum(len(files) for _,_,files in os.walk(train_dir))\n",
    "n_test  = sum(len(files) for _,_,files in os.walk(test_dir))\n",
    "print(f\"DATA_DIR    = {DATA_DIR}\")\n",
    "print(f\"Detected {num_classes} classes: {classes}\")\n",
    "print(f\"Train dir   = {train_dir} ({n_train} images)\")\n",
    "print(f\"Test dir    = {test_dir} ({n_test} images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8989d1f0",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained ViT, missing keys: ['head.weight', 'head.bias']\n"
     ]
    }
   ],
   "source": [
    "# 5) Instantiate & load pretrained ViT\n",
    "import models_vit\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from timm.layers import trunc_normal_\n",
    "\n",
    "ckpt = torch.load(WEIGHTS, map_location=\"cpu\", weights_only=False)\n",
    "ckpt_model = ckpt['model']\n",
    "\n",
    "model = models_vit.__dict__['vit_large_patch16'](\n",
    "    num_classes=num_classes,\n",
    "    drop_path_rate=0.2\n",
    ")\n",
    "# prune mismatched head & load\n",
    "state = model.state_dict()\n",
    "for k in ['head.weight','head.bias']:\n",
    "    if k in ckpt_model and ckpt_model[k].shape != state[k].shape:\n",
    "        del ckpt_model[k]\n",
    "interpolate_pos_embed(model, ckpt_model)\n",
    "msg = model.load_state_dict(ckpt_model, strict=False)\n",
    "print(\"Loaded pretrained ViT, missing keys:\", msg.missing_keys)\n",
    "if 'head.weight' in msg.missing_keys:\n",
    "    trunc_normal_(model.head.weight, std=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c29512c",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Adapter inserted: [Linear(in_features=1024, out_features=256, bias=True), ReLU(inplace=True), Dropout(p=0.1, inplace=False), Linear(in_features=256, out_features=1024, bias=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.009)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.009)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.017)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.017)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.026)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.026)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.035)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.035)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.043)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.043)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.052)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.052)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.061)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.061)\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.070)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.070)\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.078)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.078)\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.087)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.087)\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.096)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.096)\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.104)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.104)\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.113)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.113)\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.122)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.122)\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.130)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.130)\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.139)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.139)\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.148)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.148)\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.157)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.157)\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.165)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.165)\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.174)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.174)\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.183)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.183)\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.191)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.191)\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): DropPath(drop_prob=0.200)\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): DropPath(drop_prob=0.200)\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (adapter): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Insert adapters (for method='adapters')\n",
    "from torch import nn\n",
    "D = model.embed_dim\n",
    "adapter_dim = D // 4  # 1024→256 by default\n",
    "model.adapter = nn.Sequential(\n",
    "    nn.Linear(D, adapter_dim),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(adapter_dim, D),\n",
    ")\n",
    "_orig_forward = model.forward_features\n",
    "def forward_with_adapter(x):\n",
    "    feat = _orig_forward(x)\n",
    "    return feat + model.adapter(feat)\n",
    "model.forward_features = forward_with_adapter\n",
    "print(f\"✅ Adapter inserted: {list(model.adapter)}\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99d5fa6",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full TRAIN set size: 12989 images\n",
      "Full TEST set size:  3253 images\n",
      "DataLoaders → Train: 12989,  Val: 3253\n"
     ]
    }
   ],
   "source": [
    "# 7) DataLoaders & Transforms\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ── a) Transforms ───────────────────────────────────────────────────────────\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(0.2,0.2,0.1,0.05),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "# ── b) Load full TRAIN folder ────────────────────────────────────────────────\n",
    "full_train = ImageFolder(train_dir, transform=train_tf)\n",
    "print(f\"Full TRAIN set size: {len(full_train)} images\")\n",
    "\n",
    "# ── c) Optionally sub‑sample exactly SUBSET_SIZE images ──────────────────────\n",
    "SUBSET_SIZE = None   # ← set to None or len(full_train) to use all images\n",
    "if SUBSET_SIZE and SUBSET_SIZE < len(full_train):\n",
    "    idxs    = list(range(len(full_train)))\n",
    "    labels  = [full_train.samples[i][1] for i in idxs]\n",
    "    sub_idxs, _ = train_test_split(\n",
    "        idxs,\n",
    "        train_size=SUBSET_SIZE,\n",
    "        random_state=SEED,\n",
    "        stratify=labels\n",
    "    )\n",
    "    train_ds = Subset(full_train, sub_idxs)\n",
    "    print(f\"Subsampled TRAIN → {len(train_ds)} images (balanced).\")\n",
    "else:\n",
    "    train_ds = full_train\n",
    "\n",
    "# ── d) Load TEST folder as your validation set ──────────────────────────────\n",
    "val_ds = ImageFolder(test_dir, transform=val_tf)\n",
    "print(f\"Full TEST set size:  {len(val_ds)} images\")\n",
    "\n",
    "# ── e) Build DataLoaders ───────────────────────────────────────────────────\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader   = DataLoader(\n",
    "    val_ds,   batch_size=batch_size, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "print(f\"DataLoaders → Train: {len(train_ds)},  Val: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c897d5",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# 8) Transfer‐learning config helper\n",
    "def apply_transfer_config(model, method, partial_blocks=4):\n",
    "    # freeze all\n",
    "    for p in model.parameters(): p.requires_grad = False\n",
    "    # unfreeze per method\n",
    "    if method == 'linear_probe':\n",
    "        for p in model.head.parameters(): p.requires_grad = True\n",
    "    elif method == 'partial_ft':\n",
    "        for blk in model.blocks[-partial_blocks:]:\n",
    "            for p in blk.parameters(): p.requires_grad = True\n",
    "        for p in model.head.parameters(): p.requires_grad = True\n",
    "    elif method == 'full_ft':\n",
    "        for p in model.parameters(): p.requires_grad = True\n",
    "    elif method == 'adapters':\n",
    "        for n,p in model.named_parameters():\n",
    "            if n.startswith('adapter') or n.startswith('head'):\n",
    "                p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method '{method}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "989642d8",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# 9) Single‐run experiment & CSV logging\n",
    "from datetime import datetime\n",
    "import csv, time\n",
    "\n",
    "# path to your CSV\n",
    "CSV = \"fundus_transfer_experiments.csv\"\n",
    "FIELDNAMES = ['exp_no','method','val_acc','train_loss','time_s','timestamp']\n",
    "\n",
    "def run_single(exp_no, method):\n",
    "    # 1) Reload the bare ViT and pretrained weights\n",
    "    tmp = models_vit.__dict__['vit_large_patch16'](\n",
    "        num_classes=num_classes, drop_path_rate=0.2\n",
    "    )\n",
    "    interpolate_pos_embed(tmp, ckpt_model)\n",
    "    tmp.load_state_dict(\n",
    "        {k: v for k, v in ckpt_model.items() if k in tmp.state_dict()},\n",
    "        strict=False\n",
    "    )\n",
    "\n",
    "    # 2) If using adapters, copy + rebind forward to use tmp.adapter\n",
    "    if method == 'adapters':\n",
    "        tmp.adapter = model.adapter\n",
    "        orig_forward = tmp.forward_features\n",
    "        def forward_with_tmp_adapter(x):\n",
    "            feat = orig_forward(x)\n",
    "            return feat + tmp.adapter(feat)\n",
    "        tmp.forward_features = forward_with_tmp_adapter\n",
    "\n",
    "    # 3) Freeze / unfreeze per transfer‐learning method\n",
    "    apply_transfer_config(tmp, method)\n",
    "\n",
    "    # 4) Move everything (backbone + adapter) onto device\n",
    "    tmp = tmp.to(device)\n",
    "\n",
    "    print(f\"\\n▶ Starting experiment #{exp_no} — method={method}\")\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, tmp.parameters()),\n",
    "        lr=3e-5,\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 5) Time‑stamp start\n",
    "    start_time = time.time()\n",
    "\n",
    "    history = {'loss': [], 'val_acc': []}\n",
    "    for epoch in range(1, 6):\n",
    "        # — Training epoch —\n",
    "        tmp.train()\n",
    "        running_loss = 0.0\n",
    "        for imgs, labels in tqdm(train_loader,\n",
    "                                 desc=f\"[{method}] Epoch {epoch}/5 (train)\",\n",
    "                                 leave=False):\n",
    "            imgs   = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            loss = crit(tmp(imgs), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        history['loss'].append(avg_loss)\n",
    "        print(f\"  Epoch {epoch}/5 ▶ Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # — Validation epoch —\n",
    "        tmp.eval()\n",
    "        correct = total = 0\n",
    "        for imgs, labels in tqdm(val_loader,\n",
    "                                 desc=f\"[{method}] Epoch {epoch}/5 (val)\",\n",
    "                                 leave=False):\n",
    "            imgs   = imgs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            preds = tmp(imgs).argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "        history['val_acc'].append(val_acc)\n",
    "        print(f\"  Epoch {epoch}/5 ▶ Val Acc: {val_acc:.4%}\")\n",
    "\n",
    "    # 6) Measure elapsed time\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    # 7) Build and append the CSV row\n",
    "    row = {\n",
    "        'exp_no':     exp_no,\n",
    "        'method':     method,\n",
    "        'val_acc':    history['val_acc'][-1],\n",
    "        'train_loss': history['loss'][-1],\n",
    "        'time_s':     round(elapsed, 2),\n",
    "        'timestamp':  datetime.now().strftime('%Y%m%d_%H%M%S'),\n",
    "    }\n",
    "    with open(CSV, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n",
    "        writer.writerow(row)\n",
    "    print(f\">>> Logged exp#{exp_no} [{method}] → acc={row['val_acc']:.4%}\")\n",
    "\n",
    "    # 8) Return the fine‑tuned model and its history\n",
    "    return tmp, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66c91c",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment #1: linear_probe ===\n",
      "\n",
      "▶ Starting experiment #1 — method=linear_probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Train Loss: 2.0649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Val Acc: 27.7897%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Train Loss: 2.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Val Acc: 28.4968%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Train Loss: 1.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Val Acc: 30.8331%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4/5 ▶ Train Loss: 1.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4/5 ▶ Val Acc: 30.7716%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/5 ▶ Train Loss: 1.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/5 ▶ Val Acc: 30.6794%\n",
      ">>> Logged exp#1 [linear_probe] → acc=30.6794%\n",
      ">>> linear_probe: val_acc=30.6794%, loss=1.9570\n",
      "\n",
      "=== Experiment #2: partial_ft ===\n",
      "\n",
      "▶ Starting experiment #2 — method=partial_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Train Loss: 1.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Val Acc: 66.2465%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Train Loss: 0.9940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Val Acc: 76.0221%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Train Loss: 0.8063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Val Acc: 78.6658%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4/5 ▶ Train Loss: 0.7245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4/5 ▶ Val Acc: 79.8955%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/5 ▶ Train Loss: 0.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/5 ▶ Val Acc: 81.4940%\n",
      ">>> Logged exp#2 [partial_ft] → acc=81.4940%\n",
      ">>> partial_ft: val_acc=81.4940%, loss=0.6581\n",
      "\n",
      "=== Experiment #3: full_ft ===\n",
      "\n",
      "▶ Starting experiment #3 — method=full_ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Train Loss: 1.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5 ▶ Val Acc: 76.9751%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Train Loss: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2/5 ▶ Val Acc: 80.1107%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Train Loss: 0.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3/5 ▶ Val Acc: 82.0166%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[full_ft] Epoch 4/5 (train):  73%|███████▎  | 593/812 [08:56<02:11,  1.66it/s]"
     ]
    }
   ],
   "source": [
    "# 10) Run your experiment by changing exp_no & method here:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch.nn as nn\n",
    "#best_model, history = run_single(exp_no=2, method='linear_probe')\n",
    "\n",
    "# instead of overwriting best_model & history, do:\n",
    "all_models   = {}\n",
    "all_histories= {}\n",
    "\n",
    "methods = ['linear_probe','partial_ft','full_ft','adapters']\n",
    "for exp_no, method in enumerate(methods, start=1):\n",
    "    print(f\"\\n=== Experiment #{exp_no}: {method} ===\")\n",
    "    model_ft, history = run_single(exp_no=exp_no, method=method)\n",
    "    all_models[method]    = model_ft\n",
    "    all_histories[method] = history\n",
    "\n",
    "    final_acc  = history['val_acc'][-1]\n",
    "    final_loss = history['loss'][-1]\n",
    "    print(f\">>> {method}: val_acc={final_acc:.4%}, loss={final_loss:.4f}\")\n",
    "\n",
    "print(\"\\n✅ All 4 experiments complete!  Check fundus_transfer_experiments.csv for results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacde5f",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# 11) Visualize the last run’s curves\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "for method in methods:\n",
    "    sub = df[df.method==method]\n",
    "    plt.plot(sub.exp_no, sub.val_acc, marker='o', label=method)\n",
    "plt.xlabel('Experiment #')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Val Acc by Method')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f984cf",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# 12) Confusion matrix for the last run\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "chosen = 'linear_probe'   # or pick linear_probe, partial_ft, full_ft\n",
    "print(f\"←←← Confusion matrix for {chosen} →→→\")\n",
    "\n",
    "model_to_plot = all_models[chosen]\n",
    "model_to_plot.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        preds = model_to_plot(imgs).argmax(1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix — {chosen}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
